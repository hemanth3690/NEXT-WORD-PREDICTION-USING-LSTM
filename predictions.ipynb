{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from transformers import pipeline\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "DATASET_PATH = 'metamorphosis_clean.txt'\n",
    "with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus = f.read().lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        input_sequences.append(token_list[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_length = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = np.array(y)  # No need for one-hot encoding with sparse categorical loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\venka\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=128, input_length=max_sequence_length - 1),  # reduced from 256\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),  # reduced LSTM units\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64)),  # reduced from 128\n",
    "    Dropout(0.2),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 39ms/step - accuracy: 0.0478 - loss: 6.4009\n",
      "Epoch 2/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.0579 - loss: 5.7630\n",
      "Epoch 3/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.0752 - loss: 5.6053\n",
      "Epoch 4/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.0937 - loss: 5.4235\n",
      "Epoch 5/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.1148 - loss: 5.2248\n",
      "Epoch 6/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.1258 - loss: 5.0896\n",
      "Epoch 7/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 42ms/step - accuracy: 0.1388 - loss: 4.9914\n",
      "Epoch 8/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.1452 - loss: 4.8469\n",
      "Epoch 9/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.1430 - loss: 4.7743\n",
      "Epoch 10/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.1509 - loss: 4.6602\n",
      "Epoch 11/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.1519 - loss: 4.5976\n",
      "Epoch 12/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.1609 - loss: 4.5063\n",
      "Epoch 13/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.1708 - loss: 4.3909\n",
      "Epoch 14/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 52ms/step - accuracy: 0.1679 - loss: 4.3365\n",
      "Epoch 15/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.1780 - loss: 4.2620\n",
      "Epoch 16/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.1756 - loss: 4.2116\n",
      "Epoch 17/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 43ms/step - accuracy: 0.1779 - loss: 4.1375\n",
      "Epoch 18/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.1933 - loss: 4.0360\n",
      "Epoch 19/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 43ms/step - accuracy: 0.1996 - loss: 3.9662\n",
      "Epoch 20/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.2101 - loss: 3.8852\n",
      "Epoch 21/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.2110 - loss: 3.8639\n",
      "Epoch 22/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.2128 - loss: 3.8004\n",
      "Epoch 23/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 54ms/step - accuracy: 0.2229 - loss: 3.7181\n",
      "Epoch 24/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 42ms/step - accuracy: 0.2308 - loss: 3.6649\n",
      "Epoch 25/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.2397 - loss: 3.5841\n",
      "Epoch 26/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.2512 - loss: 3.5217\n",
      "Epoch 27/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.2611 - loss: 3.4444\n",
      "Epoch 28/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.2586 - loss: 3.4066\n",
      "Epoch 29/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 45ms/step - accuracy: 0.2765 - loss: 3.3197\n",
      "Epoch 30/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.2819 - loss: 3.2631\n",
      "Epoch 31/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.2935 - loss: 3.1934\n",
      "Epoch 32/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.3050 - loss: 3.1360\n",
      "Epoch 33/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.3125 - loss: 3.0998\n",
      "Epoch 34/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.3223 - loss: 3.0253\n",
      "Epoch 35/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.3312 - loss: 2.9708\n",
      "Epoch 36/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.3436 - loss: 2.9016\n",
      "Epoch 37/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.3523 - loss: 2.8646\n",
      "Epoch 38/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.3582 - loss: 2.8067\n",
      "Epoch 39/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.3667 - loss: 2.7445\n",
      "Epoch 40/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.3812 - loss: 2.6876\n",
      "Epoch 41/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.3874 - loss: 2.6374\n",
      "Epoch 42/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.4032 - loss: 2.5846\n",
      "Epoch 43/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.4119 - loss: 2.5234\n",
      "Epoch 44/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 40ms/step - accuracy: 0.4153 - loss: 2.4704\n",
      "Epoch 45/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.4225 - loss: 2.4389\n",
      "Epoch 46/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.4367 - loss: 2.3955\n",
      "Epoch 47/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.4492 - loss: 2.3243\n",
      "Epoch 48/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.4581 - loss: 2.2931\n",
      "Epoch 49/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.4704 - loss: 2.2365\n",
      "Epoch 50/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.4749 - loss: 2.1733\n",
      "Epoch 51/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 40ms/step - accuracy: 0.4860 - loss: 2.1473\n",
      "Epoch 52/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.4850 - loss: 2.1245\n",
      "Epoch 53/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 39ms/step - accuracy: 0.4938 - loss: 2.0610\n",
      "Epoch 54/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.5190 - loss: 1.9938\n",
      "Epoch 55/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.5160 - loss: 1.9890\n",
      "Epoch 56/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 47ms/step - accuracy: 0.5184 - loss: 1.9735\n",
      "Epoch 57/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 45ms/step - accuracy: 0.5296 - loss: 1.8993\n",
      "Epoch 58/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5387 - loss: 1.8791\n",
      "Epoch 59/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5472 - loss: 1.8377\n",
      "Epoch 60/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.5544 - loss: 1.7968\n",
      "Epoch 61/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5601 - loss: 1.7787\n",
      "Epoch 62/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5709 - loss: 1.7383\n",
      "Epoch 63/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5710 - loss: 1.7189\n",
      "Epoch 64/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.5846 - loss: 1.6734\n",
      "Epoch 65/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5982 - loss: 1.6252\n",
      "Epoch 66/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.5943 - loss: 1.6209\n",
      "Epoch 67/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6072 - loss: 1.5693\n",
      "Epoch 68/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 39ms/step - accuracy: 0.6111 - loss: 1.5481\n",
      "Epoch 69/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 37ms/step - accuracy: 0.6139 - loss: 1.5311\n",
      "Epoch 70/70\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - accuracy: 0.6105 - loss: 1.5326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b485bf76b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 70\n",
    "model.fit(X, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.6319 - loss: 1.4588\n",
      "Epoch 2/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6256 - loss: 1.4786\n",
      "Epoch 3/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6358 - loss: 1.4079\n",
      "Epoch 4/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.6462 - loss: 1.3853\n",
      "Epoch 5/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6492 - loss: 1.3887\n",
      "Epoch 6/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.6585 - loss: 1.3422\n",
      "Epoch 7/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 36ms/step - accuracy: 0.6654 - loss: 1.3208\n",
      "Epoch 8/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.6587 - loss: 1.3234\n",
      "Epoch 9/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.6570 - loss: 1.3073\n",
      "Epoch 10/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.6754 - loss: 1.2534\n",
      "Epoch 11/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.6800 - loss: 1.2295\n",
      "Epoch 12/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 43ms/step - accuracy: 0.6886 - loss: 1.2214\n",
      "Epoch 13/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 49ms/step - accuracy: 0.6923 - loss: 1.2018\n",
      "Epoch 14/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.6945 - loss: 1.1722\n",
      "Epoch 15/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 37ms/step - accuracy: 0.6897 - loss: 1.1788\n",
      "Epoch 16/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.7073 - loss: 1.1467\n",
      "Epoch 17/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.7093 - loss: 1.1242\n",
      "Epoch 18/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.7146 - loss: 1.0810\n",
      "Epoch 19/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7094 - loss: 1.1021\n",
      "Epoch 20/20\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.7123 - loss: 1.0823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b49764c560>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 20\n",
    "model.fit(X, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7245 - loss: 1.0656\n",
      "Epoch 2/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.7190 - loss: 1.0563\n",
      "Epoch 3/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.7349 - loss: 1.0202\n",
      "Epoch 4/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 35ms/step - accuracy: 0.7328 - loss: 1.0101\n",
      "Epoch 5/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.7406 - loss: 0.9756\n",
      "Epoch 6/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 46ms/step - accuracy: 0.7417 - loss: 0.9908\n",
      "Epoch 7/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 44ms/step - accuracy: 0.7433 - loss: 0.9544\n",
      "Epoch 8/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 38ms/step - accuracy: 0.7459 - loss: 0.9457\n",
      "Epoch 9/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.7481 - loss: 0.9419\n",
      "Epoch 10/10\n",
      "\u001b[1m632/632\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.7508 - loss: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b497b91d30>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 10\n",
    "model.fit(X, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8895 - loss: 0.4898\n",
      "Validation Accuracy: 89.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training completed! Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model.save('bilstm_model.h5')\n",
    "with open('tokenizer1.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "print(\"âœ… Training completed! Model and tokenizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BiLSTM model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load BiLSTM Model\n",
    "bilstm_model = load_model('bilstm_model.h5')\n",
    "print(\"âœ… BiLSTM model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "with open('tokenizer1.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "print(\"âœ… Tokenizer loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Load BERT fill-mask pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to store only the predicted sentence in a .txt file\n",
    "# -----------------------------------------------------------\n",
    "def store_user_data(predicted_text, filename='metamorphosis_clean.txt'):\n",
    "    \"\"\"\n",
    "    Append only the predicted text to a text file.\n",
    "    Each prediction is stored on a new line.\n",
    "    \"\"\"\n",
    "    with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(predicted_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset vocabulary\n",
    "if os.path.exists(DATASET_PATH):\n",
    "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset_words = set(f.read().split())\n",
    "else:\n",
    "    dataset_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inappropriate words filter\n",
    "BAD_WORDS = {\"damn\", \"hell\", \"shit\", \"fuck\", \"bitch\", \"bastard\", \"ass\", \"asshole\", \"dumbass\", \"jackass\", \n",
    "             \"motherfucker\", \"cock\", \"piss\", \"crap\", \"slut\", \"whore\", \"dick\", \"cunt\", \"nigger\", \n",
    "             \"retard\", \"faggot\", \"twat\", \"wanker\", \"moron\", \"idiot\", \"stupid\"}\n",
    "\n",
    "# Ensure valid words\n",
    "def is_valid_word(word):\n",
    "    return word.lower() not in BAD_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_bilstm(text, top_k=5):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length-1, padding='pre')\n",
    "    # Get the full probability distribution from the model\n",
    "    predictions = bilstm_model.predict(padded_sequence)[0]\n",
    "    \n",
    "    # Sort indices by probability (highest first)\n",
    "    sorted_indices = np.argsort(predictions)[::-1]\n",
    "    \n",
    "    # Loop over top_k predictions and return the first valid word\n",
    "    for idx in sorted_indices[:top_k]:\n",
    "        predicted_word = tokenizer.index_word.get(idx, None)\n",
    "        if predicted_word and is_valid_word(predicted_word):\n",
    "            return predicted_word\n",
    "    # If none of the top_k are valid, return a filtered indicator\n",
    "    return \"[filtered]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word_bert(text):\n",
    "    masked_text = text + \" [MASK].\"\n",
    "    predictions = fill_mask(masked_text)\n",
    "    for pred in predictions:\n",
    "        token_str = pred['token_str'].strip()\n",
    "        # Remove leading subword indicators if present\n",
    "        if token_str.startswith(\"##\"):\n",
    "            token_str = token_str[2:]\n",
    "        if is_valid_word(token_str):\n",
    "            return token_str\n",
    "    return \"[filtered]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(text):\n",
    "    words = text.split()\n",
    "    last_word = words[-1] if words else \"\"\n",
    "    if last_word in dataset_words:\n",
    "        return predict_next_word_bilstm(text)\n",
    "    else:\n",
    "        new_word = predict_next_word_bert(text)\n",
    "        if new_word != \"[filtered]\":\n",
    "            predicted_sentence = text + \" \" + new_word\n",
    "            dataset_words.update(predicted_sentence.split())\n",
    "            with open(DATASET_PATH, 'a', encoding='utf-8') as f:\n",
    "                f.write(\"\\n\" + predicted_sentence.strip())  # Save entire sentence\n",
    "        return new_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict multiple words\n",
    "def Predict_Next_Words(text, num_words):\n",
    "    predicted_sentence = text\n",
    "    for _ in range(num_words):\n",
    "        next_word = predict_next_word(predicted_sentence)\n",
    "        predicted_sentence += \" \" + next_word.strip()\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "ğŸ”¹ Input: The book was\n",
      "âœ… Predicted Sentence: The book was effects of what's been going\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "if __name__ == \"__main__\":\n",
    "    input_text = \"The book was\"\n",
    "    num_predictions = 5\n",
    "    result = Predict_Next_Words(input_text, num_predictions)\n",
    "    print(f\"\\nğŸ”¹ Input: {input_text}\\nâœ… Predicted Sentence: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\n",
      "ğŸ”¹ Input: It is raining \n",
      "âœ… Predicted Sentence: It is raining  again with\n"
     ]
    }
   ],
   "source": [
    "# Take user input\n",
    "user_input = input(\"Enter a starting phrase: \")\n",
    "num_words_to_predict = input(\"Enter the number of words to predict: \")\n",
    "\n",
    "# Ensure the second input is converted to an integer\n",
    "try:\n",
    "\tnum_words_to_predict = int(num_words_to_predict)\n",
    "\tpredicted_sentence = Predict_Next_Words(user_input, num_words_to_predict)\n",
    "\tprint(f\"\\nğŸ”¹ Input: {user_input}\\nâœ… Predicted Sentence: {predicted_sentence}\")\n",
    "except ValueError:\n",
    "\tprint(\"âŒ Error: Please enter a valid number for the number of words to predict.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
